# Semantic Patterns: Detecting AI-Washing in Corporate Disclosures

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

This project aims to identify and classify AI-related language in SEC 10-K filings to detect patterns of **"AI-washing"**â€”where companies mention artificial intelligence in vague or misleading ways. Using natural language processing (NLP), the project builds tools to detect **Actionable**, **Speculative**, and **Irrelevant** AI claims and study their relationship with financial behavior and investor response.

---

## ğŸ§  Research Goals

- Extract AI mentions from corporate filings using keyword-based filters
- Manually label a gold standard dataset of AI-related sentences
- Train a semantic classifier using SentenceBERT embeddings and class centroids
- Classify all AI sentences across thousands of 10-Ks
- Link AI narrative patterns to stock returns, patenting behavior, and litigation

---

## ğŸ“ Project Structure

This project follows the [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) structure.

```
semantic-patterns/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original 10-K filings and CRSP/Compustat data
â”‚   â”œâ”€â”€ processed/             # Final structured AI sentence datasets
â”‚   â”œâ”€â”€ validation/            # Hand-labeled sentence files, embeddings, centroids
â”‚
â”œâ”€â”€ models/                    # (Optional) Serialized model objects
â”‚
â”œâ”€â”€ notebooks/                 # EDA and analysis notebooks
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ classification/        # Sentence classification pipeline
â”‚   â”‚   â”œâ”€â”€ embed_labeled_sentences.py
â”‚   â”‚   â”œâ”€â”€ compute_centroids.py
â”‚   â”‚   â”œâ”€â”€ classify_with_centroids.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                  # Sentence extraction, filtering
â”‚   â”œâ”€â”€ plots.py               # Visualizations of sentence or label distribution
â”‚   â””â”€â”€ run_pipeline.py        # Top-level script to run all stages
â”‚
â”œâ”€â”€ tests/                     # Evaluation and accuracy testing scripts
â”‚   â””â”€â”€ evaluate_classifier_on_held_out.py
â”‚
â”œâ”€â”€ reports/                   # Exportable output for paper figures or audit
â”‚
â”œâ”€â”€ requirements.txt           # Python environment requirements
â””â”€â”€ README.md                  # This file
```

---

## ğŸ” Sentence Classification Task

AI-related sentences are classified into three categories:

| Label        | Description |
|--------------|-------------|
| **Actionable** | Concrete initiatives using AI (e.g., â€œWe deployed AI to detect fraud.â€) |
| **Speculative** | Forward-looking or vague references (e.g., â€œWe may explore AI in the future.â€) |
| **Irrelevant** | General industry trends or boilerplate (e.g., â€œAI is transforming the economy.â€) |

---

## ğŸ› ï¸ How to Run the Pipeline

### Setup

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Embedding + Centroid Pipeline

```bash
# Step 1: Generate embeddings from labeled sentences
python src/classification/embed_labeled_sentences.py

# Step 2: Compute centroids for each class
python src/classification/compute_centroids.py

# Step 3: Evaluate on held-out validation examples
python src/tests/evaluate_classifier_on_held_out.py
```

---

## ğŸ§© Extending the Project

You can plug in new sentence sources or update the label definitions using:

- `data/validation/hand_labeled_ai_sentences_labeled_cleaned_revised.csv`
- Or replace the classifier with a fine-tuned transformer model
- You can also run PCA/UMAP visualizations using `plots.py` to see cluster separation

---

## ğŸ“¬ Contact

Developer & Maintainer: Soheil Khodadadi
Project Supervisors: Thomas Walker, Kuntara Pukthuanthong

---

## ğŸ“„ License

MIT License (if applicable)
